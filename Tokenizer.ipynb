{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taeyeon02/nlp_lab/blob/main/Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b87617",
      "metadata": {
        "id": "78b87617"
      },
      "source": [
        "### 서브워드 토크나이저\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49d445a8",
      "metadata": {
        "id": "49d445a8"
      },
      "source": [
        "## BPE(Byte Pair Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba87109",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "id": "fba87109",
        "outputId": "48a0babe-7f58-4fd5-e85d-f14393be3e22"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 1"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 8, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('e', 's'): 9, ('s', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'e'): 3}\n",
            "new merge: ('e', 's')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w es t </w>': 6, 'w i d es t </w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 2"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'es'): 6, ('es', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'es'): 3}\n",
            "new merge: ('es', 't')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 3"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est'): 6, ('est', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est'): 3}\n",
            "new merge: ('est', '</w>')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 4"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('l', 'o')\n",
            "dictionary: {'lo w </w>': 5, 'lo w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 5"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('lo', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('lo', 'w')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 6"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('n', 'e')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'ne w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 7"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('ne', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('ne', 'w')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'new est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 8"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('new', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('new', 'est</w>')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 9"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('low', '</w>')\n",
            "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 10"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 pair들의 빈도수 : {('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "new merge: ('w', 'i')\n",
            "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'wi d est</w>': 3}\n"
          ]
        }
      ],
      "source": [
        "import re, collections\n",
        "from IPython.display import display, Markdown, Latex\n",
        "\n",
        "num_merges = 10 # BPE을 몇 회 수행할 것인지를 정함\n",
        "\n",
        "# BPE에 사용할 단어가 low, lower, newest, widest일 때, BPE의 입력으로 사용하는 실제 단어 집합은 아래와 같음\n",
        "dictionary = {'l o w </w>' : 5,\n",
        "         'l o w e r </w>' : 2,\n",
        "         'n e w e s t </w>':6,\n",
        "         'w i d e s t </w>':3\n",
        "         }\n",
        "\n",
        "# BPE의 코드\n",
        "def get_stats(dictionary):\n",
        "    # 유니그램의 pair들의 빈도수를 카운트\n",
        "    pairs = collections.defaultdict(int)\n",
        "    for word, freq in dictionary.items():\n",
        "        symbols = word.split()\n",
        "        for i in range(len(symbols)-1):\n",
        "            pairs[symbols[i],symbols[i+1]] += freq\n",
        "    print('현재 pair들의 빈도수 :', dict(pairs))\n",
        "    return pairs\n",
        "\n",
        "def merge_dictionary(pair, v_in):\n",
        "    v_out = {}\n",
        "    bigram = re.escape(' '.join(pair))\n",
        "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
        "    for word in v_in:\n",
        "        w_out = p.sub(''.join(pair), word)\n",
        "        v_out[w_out] = v_in[word]\n",
        "    return v_out\n",
        "\n",
        "bpe_codes = {}\n",
        "bpe_codes_reverse = {}\n",
        "\n",
        "for i in range(num_merges):\n",
        "    display(Markdown(\"### Iteration {}\".format(i + 1)))\n",
        "    pairs = get_stats(dictionary)\n",
        "    best = max(pairs, key=pairs.get)\n",
        "    dictionary = merge_dictionary(best, dictionary)\n",
        "\n",
        "    bpe_codes[best] = i\n",
        "    bpe_codes_reverse[best[0] + best[1]] = best\n",
        "\n",
        "    print(\"new merge: {}\".format(best))\n",
        "    print(\"dictionary: {}\".format(dictionary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc7992a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bc7992a",
        "outputId": "a82e6c69-f0d5-45c9-db96-fec9bdecf809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('e', 's'): 0, ('es', 't'): 1, ('est', '</w>'): 2, ('l', 'o'): 3, ('lo', 'w'): 4, ('n', 'e'): 5, ('ne', 'w'): 6, ('new', 'est</w>'): 7, ('low', '</w>'): 8, ('w', 'i'): 9}\n"
          ]
        }
      ],
      "source": [
        "print(bpe_codes) # Merge 했던 기록 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12aca2b1",
      "metadata": {
        "id": "12aca2b1"
      },
      "source": [
        "## OOV에 대처하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf035330",
      "metadata": {
        "id": "cf035330"
      },
      "outputs": [],
      "source": [
        "def get_pairs(word):\n",
        "    \"\"\"Return set of symbol pairs in a word.\n",
        "    Word is represented as a tuple of symbols (symbols being variable-length strings).\n",
        "    \"\"\"\n",
        "    pairs = set()\n",
        "    prev_char = word[0]\n",
        "    for char in word[1:]:\n",
        "        pairs.add((prev_char, char))\n",
        "        prev_char = char\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def encode(orig):\n",
        "    \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\"\"\"\n",
        "\n",
        "    word = tuple(orig) + ('</w>',)\n",
        "    display(Markdown(\"__word split into characters:__ <tt>{}</tt>\".format(word)))\n",
        "\n",
        "    pairs = get_pairs(word)    \n",
        "\n",
        "    if not pairs:\n",
        "        return orig\n",
        "\n",
        "    iteration = 0\n",
        "    while True:\n",
        "        iteration += 1\n",
        "        display(Markdown(\"__Iteration {}:__\".format(iteration)))\n",
        "\n",
        "        print(\"bigrams in the word: {}\".format(pairs))\n",
        "        bigram = min(pairs, key = lambda pair: bpe_codes.get(pair, float('inf')))\n",
        "        print(\"candidate for merging: {}\".format(bigram))\n",
        "        if bigram not in bpe_codes:\n",
        "            display(Markdown(\"__Candidate not in BPE merges, algorithm stops.__\"))\n",
        "            break\n",
        "        first, second = bigram\n",
        "        new_word = []\n",
        "        i = 0\n",
        "        while i < len(word):\n",
        "            try:\n",
        "                j = word.index(first, i)\n",
        "                new_word.extend(word[i:j])\n",
        "                i = j\n",
        "            except:\n",
        "                new_word.extend(word[i:])\n",
        "                break\n",
        "\n",
        "            if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
        "                new_word.append(first+second)\n",
        "                i += 2\n",
        "            else:\n",
        "                new_word.append(word[i])\n",
        "                i += 1\n",
        "        new_word = tuple(new_word)\n",
        "        word = new_word\n",
        "        print(\"word after merging: {}\".format(word))\n",
        "        if len(word) == 1:\n",
        "            break\n",
        "        else:\n",
        "            pairs = get_pairs(word)\n",
        "\n",
        "    # 특별 토큰인 </w>는 출력하지 않는다.\n",
        "    if word[-1] == '</w>':\n",
        "        word = word[:-1]\n",
        "    elif word[-1].endswith('</w>'):\n",
        "        word = word[:-1] + (word[-1].replace('</w>',''),)\n",
        "\n",
        "    return word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e68de93",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "3e68de93",
        "outputId": "27fd1e19-d567-44ad-bd29-384bc4d6caca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__word split into characters:__ <tt>('l', 'o', 'k', 'i', '</w>')</tt>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 1:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('i', '</w>'), ('l', 'o'), ('k', 'i'), ('o', 'k')}\n",
            "candidate for merging: ('l', 'o')\n",
            "word after merging: ('lo', 'k', 'i', '</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 2:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('i', '</w>'), ('lo', 'k'), ('k', 'i')}\n",
            "candidate for merging: ('i', '</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Candidate not in BPE merges, algorithm stops.__"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lo', 'k', 'i')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "encode(\"loki\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "781927d0",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "781927d0",
        "outputId": "1a6b1137-6a54-48cb-c428-1d5a257d5efe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__word split into characters:__ <tt>('l', 'o', 'w', 'e', 's', 't', '</w>')</tt>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 1:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('e', 's'), ('t', '</w>'), ('l', 'o'), ('o', 'w'), ('s', 't'), ('w', 'e')}\n",
            "candidate for merging: ('e', 's')\n",
            "word after merging: ('l', 'o', 'w', 'es', 't', '</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 2:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('t', '</w>'), ('l', 'o'), ('es', 't'), ('o', 'w'), ('w', 'es')}\n",
            "candidate for merging: ('es', 't')\n",
            "word after merging: ('l', 'o', 'w', 'est', '</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 3:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('l', 'o'), ('o', 'w'), ('w', 'est'), ('est', '</w>')}\n",
            "candidate for merging: ('est', '</w>')\n",
            "word after merging: ('l', 'o', 'w', 'est</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 4:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('l', 'o'), ('o', 'w'), ('w', 'est</w>')}\n",
            "candidate for merging: ('l', 'o')\n",
            "word after merging: ('lo', 'w', 'est</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 5:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('lo', 'w'), ('w', 'est</w>')}\n",
            "candidate for merging: ('lo', 'w')\n",
            "word after merging: ('low', 'est</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 6:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('low', 'est</w>')}\n",
            "candidate for merging: ('low', 'est</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Candidate not in BPE merges, algorithm stops.__"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('low', 'est')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "encode(\"lowest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c88c6fe2",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "c88c6fe2",
        "outputId": "71569ba8-3953-4253-ec03-be7f2a1c95c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__word split into characters:__ <tt>('l', 'o', 'w', 'i', 'n', 'g', '</w>')</tt>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 1:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('i', 'n'), ('l', 'o'), ('o', 'w'), ('n', 'g'), ('g', '</w>'), ('w', 'i')}\n",
            "candidate for merging: ('l', 'o')\n",
            "word after merging: ('lo', 'w', 'i', 'n', 'g', '</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 2:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('w', 'i'), ('i', 'n'), ('n', 'g'), ('g', '</w>'), ('lo', 'w')}\n",
            "candidate for merging: ('lo', 'w')\n",
            "word after merging: ('low', 'i', 'n', 'g', '</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 3:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('n', 'g'), ('low', 'i'), ('g', '</w>'), ('i', 'n')}\n",
            "candidate for merging: ('n', 'g')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Candidate not in BPE merges, algorithm stops.__"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('low', 'i', 'n', 'g')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "encode(\"lowing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6edbd983",
      "metadata": {
        "id": "6edbd983"
      },
      "source": [
        "### 센텐스피스 (SentensePiece)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b07aa5",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7b07aa5",
        "outputId": "70978a72-3189-4a26-ec89-877e084a0043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "709fa8d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "709fa8d2",
        "outputId": "4d7af7c7-5ff2-4c51-8842-dd54c2a59c35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        My family and I normally do not watch local mo...\n",
              "1        Believe it or not, this was at one time the wo...\n",
              "2        After some internet surfing, I found the \"Home...\n",
              "3        One of the most unheralded great works of anim...\n",
              "4        It was the Sixties, and anyone with long hair ...\n",
              "                               ...                        \n",
              "49995    the people who came up with this are SICK AND ...\n",
              "49996    The script is so so laughable... this in turn,...\n",
              "49997    \"So there's this bride, you see, and she gets ...\n",
              "49998    Your mind will not be satisfied by this nobud...\n",
              "49999    The chaser's war on everything is a weekly sho...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import csv\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")\n",
        "\n",
        "train_df = pd.read_csv('IMDb_Reviews.csv')\n",
        "train_df['review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb58862b",
      "metadata": {
        "id": "bb58862b"
      },
      "outputs": [],
      "source": [
        "# 센텐스피스의 입력으로 사용하기 위해서 데이터프레임을 txt 파일로 저장\n",
        "with open('imdb_review.txt', 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(train_df['review']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd04a15",
      "metadata": {
        "id": "6fd04a15"
      },
      "outputs": [],
      "source": [
        "# 센텐스피스로 단어 집합과 각 단어에 고유한 정수를 부여 (아래는 인자별 의미)\n",
        "# input : 학습시킬 파일\n",
        "# model_prefix : 만들어질 모델 이름\n",
        "# vocab_size : 단어 집합의 크기\n",
        "# model_type : 사용할 모델 (unigram(default), bpe, char, word)\n",
        "# max_sentence_length: 문장의 최대 길이\n",
        "# pad_id, pad_piece: pad token id, 값\n",
        "# unk_id, unk_piece: unknown token id, 값\n",
        "# bos_id, bos_piece: begin of sentence token id, 값\n",
        "# eos_id, eos_piece: end of sequence token id, 값\n",
        "# user_defined_symbols: 사용자 정의 토큰\n",
        "spm.SentencePieceTrainer.Train('--input=imdb_review.txt --model_prefix=imdb --vocab_size=5000 --model_type=bpe --max_sentence_length=9999')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a28bd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6a28bd2",
        "outputId": "c1089236-38f3-4122-ddca-214efb9a03b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I didn't at all think of it this way.\n",
            "['▁I', '▁didn', \"'\", 't', '▁at', '▁all', '▁think', '▁of', '▁it', '▁this', '▁way', '.']\n",
            "[41, 624, 4950, 4926, 139, 170, 378, 30, 58, 73, 413, 4945]\n",
            "\n",
            "I have waited a long time for someone to film\n",
            "['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film']\n",
            "[41, 142, 1364, 1121, 4, 668, 285, 93, 1079, 33, 91]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vocab_list = pd.read_csv('imdb.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
        "vocab_list.sample(10)\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "vocab_file = \"imdb.model\"\n",
        "sp.load(vocab_file)\n",
        "\n",
        "lines = [\n",
        "  \"I didn't at all think of it this way.\",\n",
        "  \"I have waited a long time for someone to film\"\n",
        "]\n",
        "for line in lines:\n",
        "  print(line)\n",
        "  print(sp.encode_as_pieces(line))\n",
        "  print(sp.encode_as_ids(line))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcd1c4ee",
      "metadata": {
        "id": "bcd1c4ee"
      },
      "source": [
        "### 네이버 영화 리뷰 토큰화하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4de0853",
      "metadata": {
        "id": "c4de0853"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sentencepiece as spm\n",
        "import urllib.request\n",
        "import csv\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")\n",
        "\n",
        "naver_df = pd.read_table('ratings.txt')\n",
        "\n",
        "naver_df = naver_df.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
        "\n",
        "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(naver_df['document']))\n",
        "    \n",
        "spm.SentencePieceTrainer.Train('--input=naver_review.txt --model_prefix=naver --vocab_size=5000 --model_type=bpe --max_sentence_length=9999')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a71b6e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "0a71b6e4",
        "outputId": "8bcb039e-76a4-4b49-8190-778813acf682"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0  1\n",
              "0  <unk>  0\n",
              "1    <s>  0\n",
              "2   </s>  0\n",
              "3     ..  0\n",
              "4     영화 -1\n",
              "5    ▁영화 -2\n",
              "6     ▁이 -3\n",
              "7     ▁아 -4\n",
              "8    ... -5\n",
              "9     ᄏᄏ -6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b202f3d-560a-4e0c-bab8-9c98d98b097e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>영화</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>▁영화</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>▁이</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>▁아</td>\n",
              "      <td>-4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>...</td>\n",
              "      <td>-5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ᄏᄏ</td>\n",
              "      <td>-6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b202f3d-560a-4e0c-bab8-9c98d98b097e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b202f3d-560a-4e0c-bab8-9c98d98b097e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b202f3d-560a-4e0c-bab8-9c98d98b097e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# vocab 생성이 완료되면 naver.model, naver.vocab 파일 두개가 생성\n",
        "# .vocab 에서 학습된 subwords를 확인할 수 있음\n",
        "vocab_list = pd.read_csv('naver.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
        "vocab_list[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db2f61c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db2f61c0",
        "outputId": "2b8add58-a5ab-4fbf-e6e0-168a82379fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "뭐 이딴 것도 영화냐.\n",
            "['▁뭐', '▁이딴', '▁것도', '▁영화냐', '.']\n",
            "[136, 970, 1299, 2593, 3276]\n",
            "\n",
            "진짜 최고의 영화입니다 ㅋㅋ\n",
            "['▁진짜', '▁최고의', '▁영화입니다', '▁ᄏᄏ']\n",
            "[54, 204, 825, 121]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "vocab_file = \"naver.model\"\n",
        "sp.load(vocab_file)\n",
        "\n",
        "lines = [\n",
        "  \"뭐 이딴 것도 영화냐.\",\n",
        "  \"진짜 최고의 영화입니다 ㅋㅋ\",\n",
        "]\n",
        "for line in lines:\n",
        "  print(line)\n",
        "  print(sp.encode_as_pieces(line))\n",
        "  print(sp.encode_as_ids(line))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6930a4",
      "metadata": {
        "id": "3a6930a4"
      },
      "source": [
        "### 서브워드텍스트인코더 (SubwordTextEncoder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "206bc24c",
      "metadata": {
        "id": "206bc24c"
      },
      "source": [
        "### IMDB 리뷰 토큰화하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96ec4ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d96ec4ab",
        "outputId": "9da1e636-165f-457e-ffe3-c188071dba75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        My family and I normally do not watch local mo...\n",
              "1        Believe it or not, this was at one time the wo...\n",
              "2        After some internet surfing, I found the \"Home...\n",
              "3        One of the most unheralded great works of anim...\n",
              "4        It was the Sixties, and anyone with long hair ...\n",
              "                               ...                        \n",
              "49995    the people who came up with this are SICK AND ...\n",
              "49996    The script is so so laughable... this in turn,...\n",
              "49997    \"So there's this bride, you see, and she gets ...\n",
              "49998    Your mind will not be satisfied by this nobud...\n",
              "49999    The chaser's war on everything is a weekly sho...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")\n",
        "\n",
        "train_df = pd.read_csv('IMDb_Reviews.csv')\n",
        "\n",
        "train_df['review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464e1eb0",
      "metadata": {
        "id": "464e1eb0"
      },
      "outputs": [],
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    train_df['review'], target_vocab_size=2**13)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f52e3652",
      "metadata": {
        "id": "f52e3652"
      },
      "source": [
        "### 허깅페이스 토크나이저(Huggingface Tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "139276ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "139276ea",
        "outputId": "cf38ab0c-474a-4199-a1af-db03eab6e3e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ad317d",
      "metadata": {
        "id": "b4ad317d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")\n",
        "\n",
        "naver_df = pd.read_table('ratings.txt')\n",
        "naver_df = naver_df.dropna(how='any')\n",
        "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(naver_df['document']))\n",
        "    \n",
        "tokenizer = BertWordPieceTokenizer(lowercase=False, strip_accents=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e66c9d",
      "metadata": {
        "id": "f6e66c9d"
      },
      "outputs": [],
      "source": [
        "data_file = 'naver_review.txt'\n",
        "vocab_size = 30000\n",
        "limit_alphabet = 6000\n",
        "min_frequency = 5\n",
        "\n",
        "tokenizer.train(files=data_file,\n",
        "                vocab_size=vocab_size,\n",
        "                limit_alphabet=limit_alphabet,\n",
        "                min_frequency=min_frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35c92d7",
      "metadata": {
        "id": "c35c92d7"
      },
      "outputs": [],
      "source": [
        "# vocab 저장\n",
        "tokenizer.save_model('./')\n",
        "\n",
        "# vocab 로드\n",
        "df = pd.read_fwf('vocab.txt', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9f771dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9f771dd",
        "outputId": "905ccef0-2840-461b-dcca-ec900f5a7a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토큰화 결과 : ['아', '배고', '##픈', '##데', '짜장면', '##먹고', '##싶다']\n",
            "정수 인코딩 : [2111, 20629, 3651, 3347, 24681, 7873, 7378]\n",
            "디코딩 : 아 배고픈데 짜장면먹고싶다\n"
          ]
        }
      ],
      "source": [
        "encoded = tokenizer.encode('아 배고픈데 짜장면먹고싶다')\n",
        "print('토큰화 결과 :',encoded.tokens)\n",
        "print('정수 인코딩 :',encoded.ids)\n",
        "print('디코딩 :',tokenizer.decode(encoded.ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c2e551",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71c2e551",
        "outputId": "98118713-1fcc-4977-802b-62ed9c552ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토큰화 결과 : ['커피', '한잔', '##의', '여유', '##를', '즐기', '##다']\n",
            "정수 인코딩 : [12825, 25649, 3324, 12696, 3425, 10784, 3236]\n",
            "디코딩 : 커피 한잔의 여유를 즐기다\n"
          ]
        }
      ],
      "source": [
        "encoded = tokenizer.encode('커피 한잔의 여유를 즐기다')\n",
        "print('토큰화 결과 :',encoded.tokens)\n",
        "print('정수 인코딩 :',encoded.ids)\n",
        "print('디코딩 :',tokenizer.decode(encoded.ids))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}